import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

from flask import Flask, render_template_string
from flask_socketio import SocketIO
import socket
import threading
import cv2
import mediapipe as mp
import time
import numpy as np
import pydirectinput

# =================é…ç½®åŒºåŸŸ=================
CAMERA_INDEX = 0   
ROTATE_TYPE = cv2.ROTATE_90_CLOCKWISE 
CAM_W, CAM_H = 640, 480

# åˆ¤å®šèŒƒå›´ (Xè½´)
ROI_X_MIN, ROI_X_MAX = 0.05, 0.95

# ã€å…³é”®è®¾ç½®ã€‘Air åˆ¤å®šé«˜åº¦èŒƒå›´ (Yè½´)
# 0.0=é¡¶ç«¯, 1.0=åº•ç«¯
# æˆ‘ä»¬å–ä¸‹åŠå±ï¼šä» 0.5 (ä¸­é—´) åˆ° 1.0 (åº•éƒ¨)
AIR_TOP_LIMIT = 0.5   # åˆ¤å®šåŒºé¡¶ç«¯ (IR6çš„ä¸Šé™)
AIR_BOTTOM_LIMIT = 1.0 # åˆ¤å®šåŒºåº•ç«¯ (IR1çš„ä¸‹é™)

# å¯¹åº” sega.ini çš„æŒ‰é”®æ˜ å°„ (ä»ä¸‹åˆ°ä¸Š IR1 -> IR6)
# æ˜ å°„: m, n, o, p, q, r
IR_KEY_MAP = {
    1: 'm', 
    2: 'n', 
    3: 'o', 
    4: 'p', 
    5: 'q', 
    6: 'r'
}

MOTION_SENSITIVITY = 25 
MOTION_AREA_MIN = 500 

HOST_IP = '0.0.0.0' 
PORT = 3000

pydirectinput.PAUSE = 0
pydirectinput.FAILSAFE = False
# =========================================

HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Chuni Half-Screen IR</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        body { background: #000; overflow: hidden; color: #fff; font-family: monospace; user-select: none; }
        #status { position: fixed; top: 10px; left: 50%; transform: translateX(-50%); border: 1px solid #555; padding: 5px; background: rgba(0,0,0,0.5); pointer-events: none; z-index: 99; }
        #keyboard { display: flex; height: 100vh; width: 100vw; }
        .key { flex: 1; background: #111; box-shadow: inset 1px 0 0 0 rgba(255,255,255,0.1); touch-action: none; }
        .key:nth-child(4n) { box-shadow: inset 2px 0 0 0 rgba(255, 215, 0, 0.6); }
        .key.pressed { background: linear-gradient(to bottom, #00c6ff, #0072ff); }
    </style>
</head>
<body>
    <div id="status">Connecting...</div>
    <div id="keyboard"></div>
    <script>
        try {
            const socket = io({ transports: ['websocket'], upgrade: false, reconnectionDelay: 1000 });
            const statusDiv = document.getElementById('status');
            const keyMap = ['l','k','j','i', 'h','g','f','e', 'd','c','b','a', '9','8','7','6'];
            
            keyMap.forEach(k => {
                let d = document.createElement('div'); d.className = 'key'; d.dataset.key = k;
                document.getElementById('keyboard').appendChild(d);
            });

            socket.on('connect', () => { statusDiv.textContent = "READY (Half-Screen IR)"; statusDiv.style.color = "#0f0"; });
            
            const currentHeldKeys = new Set();
            function updateVisuals() {
                document.querySelectorAll('.key').forEach(el => {
                    el.classList.toggle('pressed', currentHeldKeys.has(el.dataset.key));
                });
            }

            function handleTouch(e) {
                e.preventDefault(); 
                const newHeldKeys = new Set();
                const screenW = window.innerWidth;
                const keyWidth = screenW / 16;
                const edgeThreshold = keyWidth * 0.20; 

                Array.from(e.touches).forEach(t => {
                    let mainIndex = Math.floor(t.clientX / keyWidth);
                    if (mainIndex >= 0 && mainIndex < 16) {
                        newHeldKeys.add(keyMap[mainIndex]);
                        let offset = t.clientX % keyWidth;
                        if (offset < edgeThreshold && mainIndex > 0) newHeldKeys.add(keyMap[mainIndex - 1]);
                        if (offset > (keyWidth - edgeThreshold) && mainIndex < 15) newHeldKeys.add(keyMap[mainIndex + 1]);
                    }
                });

                newHeldKeys.forEach(k => { if (!currentHeldKeys.has(k)) socket.emit('keydown', k); });
                currentHeldKeys.forEach(k => { if (!newHeldKeys.has(k)) socket.emit('keyup', k); });
                currentHeldKeys.clear();
                newHeldKeys.forEach(k => currentHeldKeys.add(k));
                updateVisuals();
            }
            ['touchstart', 'touchmove', 'touchend', 'touchcancel'].forEach(evt => document.addEventListener(evt, handleTouch, {passive: false}));
            setInterval(() => { if (socket.connected) socket.emit('sync_keys', Array.from(currentHeldKeys)); }, 300);
        } catch(e) {}
    </script>
</body>
</html>
"""

app = Flask(__name__)
socketio = SocketIO(app, cors_allowed_origins="*", max_decode_packets=500, async_mode='threading')

server_pressed_keys = set()
lock = threading.Lock()

@app.route('/')
def index(): return render_template_string(HTML_TEMPLATE)

@socketio.on('connect')
def handle_connect(): print("âœ… DEVICE CONNECTED!")

@socketio.on('keydown')
def handle_keydown(key):
    with lock:
        if key not in server_pressed_keys:
            pydirectinput.keyDown(key) 
            server_pressed_keys.add(key)

@socketio.on('keyup')
def handle_keyup(key):
    with lock:
        if key in server_pressed_keys:
            pydirectinput.keyUp(key)
            server_pressed_keys.remove(key)

@socketio.on('sync_keys')
def handle_sync(client_keys_list):
    client_keys = set(client_keys_list)
    with lock:
        stuck_keys = server_pressed_keys - client_keys
        for k in stuck_keys:
            pydirectinput.keyUp(k)
            server_pressed_keys.remove(k)

def get_local_ips():
    ips = []
    try:
        hostname = socket.gethostname()
        for ip in socket.gethostbyname_ex(hostname)[2]:
            if not ip.startswith("127."): ips.append(ip)
    except: pass
    return ips

# --- æ ¸å¿ƒä¿®æ”¹ï¼šä¸‹åŠå± 6 ç­‰åˆ†é€»è¾‘ ---
def get_ir_level(y_pos):
    # y_pos: 0.0 (é¡¶) ~ 1.0 (åº•)
    
    # 1. å¦‚æœæ‰‹å¤ªé«˜ (è¶…è¿‡ä¸­çº¿)ï¼Œè§†ä¸ºæœªè§¦å‘
    if y_pos < AIR_TOP_LIMIT: return 0 
    # 2. å¦‚æœæ‰‹å¤ªä½ (ä½äºåº•çº¿)ï¼Œè§†ä¸º IR1 (ä¿®æ­£è¯¯å·®)
    if y_pos > AIR_BOTTOM_LIMIT: return 1
    
    # 3. è®¡ç®—æœ‰æ•ˆåŒºåŸŸé«˜åº¦ (0.5)
    valid_height = AIR_BOTTOM_LIMIT - AIR_TOP_LIMIT
    
    # 4. è®¡ç®—æ‰‹è·ç¦»åº•éƒ¨çš„è·ç¦» (è·ç¦»åº•éƒ¨è¶Šè¿œï¼ŒIRç­‰çº§è¶Šé«˜)
    # distance_up: 0.0 (åœ¨åº•éƒ¨) ~ 0.5 (åœ¨ä¸­é—´)
    distance_up = AIR_BOTTOM_LIMIT - y_pos
    
    # 5. æ˜ å°„åˆ° 1-6
    # level = (distance_up / valid_height) * 6
    # +1 æ˜¯å› ä¸º int å‘ä¸‹å–æ•´ï¼Œæˆ‘ä»¬éœ€è¦ 1-6
    level = int((distance_up / valid_height) * 6) + 1
    
    return max(1, min(6, level))

def run_camera_loop():   
    print("ğŸ“· Camera starting (Bottom-Half IR Mode)...")
    cap = cv2.VideoCapture(CAMERA_INDEX)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAM_W)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_H)

    mp_hands = mp.solutions.hands
    
    active_ir_level = 0 
    last_ir_level = 0   
    debounce_frames = 2 
    debounce_timer = 0
    prev_gray = None

    with mp_hands.Hands(max_num_hands=2, model_complexity=0, min_detection_confidence=0.3, min_tracking_confidence=0.3) as hands:
        while cap.isOpened():
            success, image = cap.read()
            if not success: 
                time.sleep(0.01)
                continue

            if ROTATE_TYPE is not None: image = cv2.rotate(image, ROTATE_TYPE)
            
            h, w, c = image.shape
            
            # è¿™é‡Œçš„ air_y_threshold è®¾ä¸ºä¸­é—´çº¿ (0.5)ï¼Œç”¨äºåŠ¨æ€æ£€æµ‹èŒƒå›´
            mid_y = int(h * AIR_TOP_LIMIT)

            current_frame_level = 0 

            # ==========================================
            # 1. åŠ¨æ€æ£€æµ‹ (è®¡ç®—é‡å¿ƒ Y)
            # ==========================================
            # åªæ£€æµ‹ä¸‹åŠå± (mid_y åˆ° h)
            roi_frame = image[mid_y:h, 0:w]
            gray = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (21, 21), 0)
            
            motion_y = -1 
            
            if prev_gray is not None:
                frame_delta = cv2.absdiff(prev_gray, gray)
                thresh = cv2.threshold(frame_delta, MOTION_SENSITIVITY, 255, cv2.THRESH_BINARY)[1]
                
                M = cv2.moments(thresh)
                if M["m00"] > MOTION_AREA_MIN: 
                    # è®¡ç®—ç›¸å¯¹äº roi çš„ cy
                    cy_roi = int(M["m01"] / M["m00"])
                    # è½¬æ¢å›å…¨å›¾åæ ‡ (åŠ ä¸Š mid_y åç§»)
                    cy_global = cy_roi + mid_y
                    
                    motion_y = cy_global / h 
                    
                    cx_roi = int(M["m10"] / M["m00"])
                    cv2.circle(image, (cx_roi, cy_global), 20, (255, 0, 0), 2)
            
            prev_gray = gray

            # ==========================================
            # 2. AI æ£€æµ‹ (æ‰‹è…• Y)
            # ==========================================
            hand_y = -1
            image.flags.writeable = False
            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            image.flags.writeable = True

            if results.multi_hand_landmarks:
                min_y = 1.0 # æ‰¾æœ€é«˜çš„æ‰‹ (Yå€¼æœ€å°)
                found = False
                for hl in results.multi_hand_landmarks:
                    wrist = hl.landmark[0]
                    # å¿…é¡»åœ¨ X èŒƒå›´å†…ï¼Œä¸”åœ¨ä¸‹åŠå± (y > 0.5)
                    if ROI_X_MIN < wrist.x < ROI_X_MAX and wrist.y > AIR_TOP_LIMIT:
                        if wrist.y < min_y:
                            min_y = wrist.y
                            found = True
                        cv2.circle(image, (int(wrist.x*w), int(wrist.y*h)), 15, (0, 255, 0), -1)
                if found: hand_y = min_y

            # ==========================================
            # 3. èåˆåˆ¤å®š
            # ==========================================
            final_y = -1
            if hand_y != -1: final_y = hand_y
            elif motion_y != -1: final_y = motion_y
            
            if final_y != -1:
                current_frame_level = get_ir_level(final_y)
            else:
                current_frame_level = 0

            # ==========================================
            # ç»˜åˆ¶ UI ç½‘æ ¼ (ä»ä¸­é—´ç”»åˆ°åº•éƒ¨)
            # ==========================================
            # è®¡ç®—æ¯å±‚çš„é«˜åº¦ (åƒç´ )
            segment_px = (h - mid_y) / 6
            
            # ç”»é¡¶éƒ¨åˆ†ç•Œçº¿ (è“çº¿)
            cv2.line(image, (0, mid_y), (w, mid_y), (255, 0, 0), 2)
            cv2.putText(image, "AIR LIMIT (50%)", (10, mid_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)

            for i in range(1, 7):
                # IR1 åœ¨æœ€åº•ä¸‹ï¼ŒIR6 åœ¨æœ€ä¸Šé¢(mid_yé™„è¿‘)
                # è®¡ç®—æ¯å±‚çº¿çš„ Y åæ ‡
                # IR6 çš„é¡¶çº¿æ˜¯ mid_y
                # IR1 çš„é¡¶çº¿æ˜¯ h - seg
                # å½“å‰å±‚çš„é¡¶çº¿:
                level_top_y = int(h - (i * segment_px))
                
                color = (0, 255, 255) if i == current_frame_level else (50, 50, 50)
                thickness = 2 if i == current_frame_level else 1
                
                cv2.line(image, (0, level_top_y), (w, level_top_y), color, thickness)
                # æ–‡å­—ç”»åœ¨çº¿ä¸Šæ–¹
                cv2.putText(image, f"IR{i}", (10, level_top_y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            # ==========================================
            # 4. è¾“å…¥æ‰§è¡Œ
            # ==========================================
            if current_frame_level > 0:
                active_ir_level = current_frame_level
                debounce_timer = debounce_frames
            elif debounce_timer > 0:
                debounce_timer -= 1
            else:
                active_ir_level = 0

            if active_ir_level != last_ir_level:
                if last_ir_level > 0:
                    pydirectinput.keyUp(IR_KEY_MAP[last_ir_level])
                if active_ir_level > 0:
                    new_key = IR_KEY_MAP[active_ir_level]
                    pydirectinput.keyDown(new_key)
                    print(f"IR{active_ir_level} ({new_key})")
            
            last_ir_level = active_ir_level

            cv2.imshow('Chuni Half-IR', image)
            if cv2.waitKey(1) & 0xFF == 27: break
    
    cap.release()
    cv2.destroyAllWindows()
    os._exit(0)

if __name__ == '__main__':
    ips = get_local_ips()
    print('\n' + '='*60)
    print('ğŸš€ ä¸‹åŠå± 6 åˆ†å‰²æ¨¡å¼ (Bottom to 50%)')
    print('âš ï¸  æ˜ å°„é”®: m, n, o, p, q, r')
    print('='*60)
    for ip in ips:
        print(f' ğŸ‘‰ http://{ip}:{PORT}')
    print('='*60 + '\n')

    t = threading.Thread(target=lambda: socketio.run(app, host=HOST_IP, port=PORT, debug=False))
    t.daemon = True
    t.start()
    
    try:
        run_camera_loop()
    except KeyboardInterrupt: pass
    except Exception as e: print(f"Error: {e}")
    finally:
        os._exit(0)